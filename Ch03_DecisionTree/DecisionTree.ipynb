{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the leaf node in which has impurity, we determine the class based on the majority of classes\n",
    "def majorityCount(classList):\n",
    "    labelKeys, labelCounts = np.unique(classList, return_counts=True)\n",
    "    majorityClass = labelKeys[np.argsort(labelCounts)[-1]]\n",
    "    return majorityClass\n",
    "\n",
    "\n",
    "def calcEntropy(datasets):\n",
    "    numEntries = len(datasets)\n",
    "    \"\"\"\n",
    "    labels = datasets[:, -1]\n",
    "    labelKeys, labelCounts = np.unique(labels, return_counts=True)\n",
    "    entropy = 0\n",
    "    for key, count in zip(labelKeys, labelCounts):\n",
    "        prob = count / numEntries\n",
    "        entropy += -prob * log(prob, 2)\n",
    "    \"\"\"\n",
    "    labelCounts = {}\n",
    "    for featVect in datasets: #the the number of unique elements and their occurance\n",
    "        currentLabel = str(featVect[-1])\n",
    "        if currentLabel not in labelCounts.keys():\n",
    "            labelCounts[currentLabel] = 0 # construct a new count for this label key\n",
    "        labelCounts[currentLabel] += 1\n",
    "    \n",
    "    entropy = 0\n",
    "    for key in labelCounts.keys():\n",
    "        prob = labelCounts[key] / numEntries\n",
    "        entropy += - prob * log(prob, 2)\n",
    "    return entropy\n",
    "\n",
    "# splitting each attribute(column) based on different features:瓜的色泽是青绿乌黑还是浅白\n",
    "def splitDataSet(datasets, featureAxis, featureValue):\n",
    "    \"\"\"\n",
    "    Description:split a single feature based on its different feature values;\n",
    "    Inputs:\n",
    "    data:input data in a certain node\n",
    "    featureAxis: Nr. i.th feature/attribute of data\n",
    "    featureValue: all the categorical values in this feature\n",
    "    \n",
    "    return: splitted subdatasets but pulls away this feature dimension,\n",
    "            convinent for next tree split.\n",
    "    \"\"\"\n",
    "    remainData = []\n",
    "    for entry in datasets:\n",
    "        if entry[featureAxis] == featureValue:\n",
    "            reducedVector = entry[:featureAxis]\n",
    "            reducedVector.extend(entry[featureAxis + 1:])\n",
    "            remainData.append(reducedVector)\n",
    "    return remainData\n",
    "    \n",
    "\n",
    "# select the \"best\" feature to split\n",
    "def bestFeatureToSplit(datasets):\n",
    "    numFeatures = len(datasets[0]) - 1  # number of features\n",
    "    baseEntropy = calcEntropy(datasets)\n",
    "    bestInfoGain = 0\n",
    "    bestFeatureIndex = 0\n",
    "    for i in range(numFeatures):\n",
    "        newEntropy = 0\n",
    "        featureVector = [data[i] for data in datasets]\n",
    "        featureSets = np.unique(featureVector)\n",
    "        for featureValue in featureSets:\n",
    "            remainData = splitDataSet(datasets, i, featureValue)\n",
    "            prob = len(remainData) / float(len(datasets))\n",
    "            newEntropy += - prob * calcEntropy(remainData)\n",
    "        reducedEntropy = baseEntropy - newEntropy  # reduction od impuroty\n",
    "        if reducedEntropy > bestInfoGain:\n",
    "            bestInfoGain = reducedEntropy\n",
    "            bestFeatureIndex = i\n",
    "    return bestFeatureIndex\n",
    "\n",
    "def createTree(datasets, featureSets):\n",
    "    \"\"\"\n",
    "    datasets: data colums plus a colum of labels\n",
    "    featureSets: a set including all names of features/attributes\n",
    "    \"\"\"\n",
    "    classLabels = [data[-1] for data in datasets]\n",
    "    if len(datasets[0]) == 1:  # after traversing all of attributes\n",
    "        return majorityCount(classLabels)\n",
    "    elif len(classLabels[0]) == len(np.unique(classLabels)): # all the elements in this node belong to the same class\n",
    "        return classLabels[0]\n",
    "    else:\n",
    "        bestFeature = bestFeatureToSplit(datasets)  # best splitting feature\n",
    "        bestFeatLabel = featureSets[bestFeature]  # String variable\n",
    "        del(featureSets[bestFeature]) # sub feature sets excluding the former best feature name\n",
    "        \n",
    "        myTree = {bestFeatLabel: {}}  # 嵌套字典\n",
    "        featureVector = [data[bestFeature] for data in datasets]\n",
    "        uniqueValue = np.unique(featureVector)\n",
    "        for value in uniqueValue:\n",
    "            subFeatureSets = featureSets[:]\n",
    "            remainData = splitDataSet(datasets, bestFeature, value)\n",
    "            myTree[bestFeatLabel][value] = createTree(remainData, subFeatureSets)\n",
    "        return myTree        \n",
    "    \n",
    "def classify(inputTree, featureSets, testVector):\n",
    "    \"\"\"\n",
    "    Input a test vector and predict the class label\n",
    "    \"\"\"\n",
    "    firstSplitStr = list(inputTree.keys())[0]  # extract the outermost layer of key\n",
    "    index = featureSets.index(firstSplitStr)  # this string keys refers to which index in featureSets\n",
    "    featureKey = testVector[index]\n",
    "    secondDict = inputTree[firstSplitStr]\n",
    "    valueOfFeatKey = secondDict[featureKey]\n",
    "    if isinstance(valueOfFeatKey, dict): # whether valueOfFeatKey is a dictionary\n",
    "        classLabel = classify(valueOfFeatKey, featureSets, testVector)\n",
    "    else:\n",
    "        classLabel = valueOfFeatKey\n",
    "    return classLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'flippers': {0: {'no surfacing': {1: 'no'}}, 1: {'no surfacing': {0: 'no', 1: 'yes'}}}}\n"
     ]
    }
   ],
   "source": [
    "def createDataSet():\n",
    "    dataSet = [[1, 1, 'yes'],\n",
    "               [1, 1, 'yes'],\n",
    "               [1, 0, 'no'],\n",
    "               [0, 1, 'no'],\n",
    "               [0, 1, 'no']]\n",
    "    labels = ['no surfacing','flippers']\n",
    "    #change to discrete values                             \n",
    "    return dataSet, labels\n",
    "myDat, labels = createDataSet()\n",
    "myTree = createTree(myDat, labels)\n",
    "print(myTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "myDat, labels = createDataSet()\n",
    "classLabel = classify(myTree, labels, [1,1])\n",
    "print(classLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['young', 'myope', 'no', 'reduced', 'no lenses'],\n",
       " ['young', 'myope', 'no', 'normal', 'soft'],\n",
       " ['young', 'myope', 'yes', 'reduced', 'no lenses'],\n",
       " ['young', 'myope', 'yes', 'normal', 'hard'],\n",
       " ['young', 'hyper', 'no', 'reduced', 'no lenses'],\n",
       " ['young', 'hyper', 'no', 'normal', 'soft'],\n",
       " ['young', 'hyper', 'yes', 'reduced', 'no lenses'],\n",
       " ['young', 'hyper', 'yes', 'normal', 'hard'],\n",
       " ['pre', 'myope', 'no', 'reduced', 'no lenses'],\n",
       " ['pre', 'myope', 'no', 'normal', 'soft'],\n",
       " ['pre', 'myope', 'yes', 'reduced', 'no lenses'],\n",
       " ['pre', 'myope', 'yes', 'normal', 'hard'],\n",
       " ['pre', 'hyper', 'no', 'reduced', 'no lenses'],\n",
       " ['pre', 'hyper', 'no', 'normal', 'soft'],\n",
       " ['pre', 'hyper', 'yes', 'reduced', 'no lenses'],\n",
       " ['pre', 'hyper', 'yes', 'normal', 'no lenses'],\n",
       " ['presbyopic', 'myope', 'no', 'reduced', 'no lenses'],\n",
       " ['presbyopic', 'myope', 'no', 'normal', 'no lenses'],\n",
       " ['presbyopic', 'myope', 'yes', 'reduced', 'no lenses'],\n",
       " ['presbyopic', 'myope', 'yes', 'normal', 'hard'],\n",
       " ['presbyopic', 'hyper', 'no', 'reduced', 'no lenses'],\n",
       " ['presbyopic', 'hyper', 'no', 'normal', 'soft'],\n",
       " ['presbyopic', 'hyper', 'yes', 'reduced', 'no lenses'],\n",
       " ['presbyopic', 'hyper', 'yes', 'normal', 'no lenses']]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lensesLabels = ['age', 'prescript', 'astigmatic', 'tearRate']\n",
    "\n",
    "# open the file\n",
    "file = open(\"lenses.txt\")\n",
    "arrayOfLines = file.readlines()\n",
    "datasets = []\n",
    "for line in arrayOfLines:\n",
    "    line = line.strip()\n",
    "    listFromLine = line.split('\\t')\n",
    "    datasets.append(listFromLine)\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': {'pre': {'prescript': {'hyper': {'astigmatic': {'no': {'tearRate': {'normal': 'soft',\n",
       "        'reduced': 'no lenses'}},\n",
       "      'yes': {'tearRate': {'normal': 'no lenses', 'reduced': 'no lenses'}}}},\n",
       "    'myope': {'astigmatic': {'no': {'tearRate': {'normal': 'soft',\n",
       "        'reduced': 'no lenses'}},\n",
       "      'yes': {'tearRate': {'normal': 'hard', 'reduced': 'no lenses'}}}}}},\n",
       "  'presbyopic': {'prescript': {'hyper': {'astigmatic': {'no': {'tearRate': {'normal': 'soft',\n",
       "        'reduced': 'no lenses'}},\n",
       "      'yes': {'tearRate': {'normal': 'no lenses', 'reduced': 'no lenses'}}}},\n",
       "    'myope': {'astigmatic': {'no': {'tearRate': {'normal': 'no lenses',\n",
       "        'reduced': 'no lenses'}},\n",
       "      'yes': {'tearRate': {'normal': 'hard', 'reduced': 'no lenses'}}}}}},\n",
       "  'young': {'prescript': {'hyper': {'astigmatic': {'no': {'tearRate': {'normal': 'soft',\n",
       "        'reduced': 'no lenses'}},\n",
       "      'yes': {'tearRate': {'normal': 'hard', 'reduced': 'no lenses'}}}},\n",
       "    'myope': {'astigmatic': {'no': {'tearRate': {'normal': 'soft',\n",
       "        'reduced': 'no lenses'}},\n",
       "      'yes': {'tearRate': {'normal': 'hard', 'reduced': 'no lenses'}}}}}}}}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lensesLabels = ['age', 'prescript', 'astigmatic', 'tearRate']\n",
    "trainingTree = createTree(datasets, lensesLabels)\n",
    "trainingTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hard'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lensesLabels = ['age', 'prescript', 'astigmatic', 'tearRate']\n",
    "testVector = ['young', 'myope', 'yes', 'normal']\n",
    "classLabel = classify(trainingTree, lensesLabels, testVector)\n",
    "classLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
